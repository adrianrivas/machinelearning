{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poOIX69uD01V"
      },
      "source": [
        "Análisis de sentimientos de mensajes en Amazon usando Naive Bayes\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H71rIiruD01f"
      },
      "source": [
        "El archivo que se encuentra disponible en el link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRN6Ck_SD01g"
      },
      "source": [
        "https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/amazon_cells_labelled.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lskoxvDCD01h"
      },
      "source": [
        "contiene mensajes escritos por los usuarios para productos comprados en Amazon y su valoración (positiva, negativa e indeterminada). En este laboratorio se debe construir un clasificador bayesiano que debe ser entrenado con los mensajes valorados, el cual debe ser posteriormente utilizado para valorar los mensajes con valoración indeterminada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a5VkMqc5D01i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14609"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Cargue el archivo usando Pandas e imprima la cantidad de\n",
        "# registros\n",
        "#\n",
        "# Rta/\n",
        "# 14609\n",
        "#\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "rows = pd.read_csv(\"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/amazon_cells_labelled.tsv\", sep='\\t', header=None)\n",
        "\n",
        "rows.rename(columns={0:'message', 1:'qualification'}, inplace=True)\n",
        "\n",
        "len(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AK-AferZD01k"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I try not to adjust the volume setting to avoid that I turn off the call button which is situated just below the volume adjustment knob.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Imprima el primer mensaje de texto.\n",
        "#\n",
        "# Rta/\n",
        "# 'I try not to adjust the volume setting to avoid that I turn off the call button which is situated just below the volume adjustment knob.'\n",
        "#\n",
        "\n",
        "rows['message'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-hEFDBH3D01l"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13609"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Imprima la cantidad de mensajes con NaN\n",
        "#\n",
        "# Rta/\n",
        "# 13609\n",
        "#\n",
        "\n",
        "count_null = []\n",
        "\n",
        "for q in range(len(rows['qualification'])):\n",
        "    if pd.isna(rows['qualification'][q]) == True:\n",
        "        count_null.append([rows['message'][q], rows['qualification'][q]])\n",
        "\n",
        "len(count_null)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nWrckEfdD01m"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Imprima la cantidad de mensajes con valoración igual a 1.0\n",
        "#\n",
        "# Rta/\n",
        "# 500\n",
        "#\n",
        "count_positive = []\n",
        "\n",
        "for q in range(len(rows['qualification'])):\n",
        "    if rows['qualification'][q] == 1.0:\n",
        "        count_positive.append([rows['message'][q], rows['qualification'][q]])\n",
        "\n",
        "len(count_positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IfFjtES8D01n"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Imprima la cantidad de mensajes con valoración igual a 0.0\n",
        "#\n",
        "# Rta/\n",
        "# 500\n",
        "#\n",
        "\n",
        "count_negative = []\n",
        "\n",
        "for q in range(len(rows['qualification'])):\n",
        "    if rows['qualification'][q] == 0.0:\n",
        "        count_negative.append([rows['message'][q], rows['qualification'][q]])\n",
        "\n",
        "len(count_negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4rjwTex_D01p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Genere un nuevo dataset que contenga únicamente los registros\n",
        "# con valoración positiva o negativa e imprima su longitud\n",
        "#\n",
        "# Rta/\n",
        "# 1000\n",
        "#\n",
        "\n",
        "new_rows = rows.copy()\n",
        "new_rows = new_rows.dropna(subset=['qualification'])\n",
        "len(new_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9UN9KkD-D01q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'so there is no way for me to plug it in here in the us unless i go by a converter.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Genere una nueva columna en el nuevo dataset computada como\n",
        "# el resultado de aplicar el stemmer de Porter al mensaje e\n",
        "# imprima el primer mensaje transformado\n",
        "#\n",
        "# Rta/\n",
        "# 'so there is no way for me to plug it in here in the us unless i go by a converter.'\n",
        "#\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "new_rows['message_stemmed'] = new_rows.message.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
        "\n",
        "new_rows['message_stemmed'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GGiWMpZ9D01r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1554"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Construya la matriz de terminos del documento considerando\n",
        "# las palabras que tengan una frecuencia entre el 0.1% y el 98%,\n",
        "# y que esten unicamente conformadas por letras.\n",
        "#\n",
        "# Imprima el tamaño del vocabulario.\n",
        "#\n",
        "# Rta/\n",
        "# 1554\n",
        "#\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# messages_splited = []\n",
        "\n",
        "# for k in range(len(message_stemmed)):\n",
        "#     message_stemmed[k] = str(message_stemmed[k])\n",
        "#     messages_splited.append(message_stemmed[k].split(\" \"))\n",
        "\n",
        "# new_rows['message_splited'] = messages_splited\n",
        "\n",
        "count_vect = CountVectorizer(\n",
        "    analyzer=\"word\",                \n",
        "    lowercase=True,                 \n",
        "    stop_words=\"english\",           \n",
        "    #token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\", \n",
        "    binary=True,                    \n",
        "    max_df=0.98,                     \n",
        "    min_df=0.001,                       \n",
        ")\n",
        "\n",
        "dtm = count_vect.fit_transform(new_rows.message_stemmed)\n",
        "\n",
        "vocabulary = count_vect.get_feature_names()\n",
        "\n",
        "len(vocabulary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fmQ0_KmfD01s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0    52.2\n",
              "0.0    47.8\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Construya un clasificador bayesiano que use los primeros\n",
        "# 500 patrones para entrenamiento y los últimos 500 para\n",
        "# prueba, e imprima el porcentaje de datos para cada clase\n",
        "# para la muestra de entrenamiento-\n",
        "#\n",
        "# Rta/\n",
        "# 1.0    52.2\n",
        "# 0.0    47.8\n",
        "# Name: label, dtype: float64\n",
        "#\n",
        "\n",
        "new_rows.rename(columns={'qualification':'label'}, inplace=True)\n",
        "\n",
        "X_train = dtm[\n",
        "    0:500,\n",
        "]\n",
        "X_test = dtm[\n",
        "    500:,\n",
        "]\n",
        "\n",
        "y_train_true = new_rows.label[:500]\n",
        "y_test_true = new_rows.label[500:]\n",
        "\n",
        "data_train = round(100 * y_train_true.value_counts() / sum(y_train_true.value_counts()), 1)\n",
        "\n",
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6ltekyqyD01s"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    52.2\n",
              "1.0    47.8\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Imprima el porcentaje de datos para cada clase para la muestra\n",
        "# de prueba, redondeado a un decimal.\n",
        "#\n",
        "# Rta/\n",
        "# 0.0    52.2\n",
        "# 1.0    47.8\n",
        "# Name: label, dtype: float64\n",
        "#\n",
        "\n",
        "data_test = round(100 * y_test_true.value_counts() / sum(y_test_true.value_counts()), 1)\n",
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bI24aRLtD01t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[214,  25],\n",
              "       [  1, 260]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Cree un clasificador de Bayes y entrenelo. Realice el pronostico\n",
        "# para la muestra de entrenamiento y compute la matriz de confusion\n",
        "#\n",
        "# Rta/\n",
        "# array([[214,  25],\n",
        "#        [  1, 260]])\n",
        "#\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "clf = BernoulliNB()\n",
        "\n",
        "clf.fit(X_train, y_train_true)\n",
        "\n",
        "y_test_pred = clf.predict(X_train)\n",
        "\n",
        "cm_train = confusion_matrix(y_true=y_train_true, y_pred=y_test_pred)\n",
        "cm_train.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rNUT-S1vD01u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[153, 108],\n",
              "       [ 32, 207]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Realice el pronóstico para la muestra de entrenamiento y compute\n",
        "# la matriz de confusión\n",
        "#\n",
        "# Rta/\n",
        "# array([[153, 108],\n",
        "#        [ 32, 207]])\n",
        "#\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "cm_test = confusion_matrix(y_true=y_test_true, y_pred=y_test_pred)\n",
        "cm_test.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uYvnagqhD01v"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8284"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Realice el pronostico para los mensajes con valoración \n",
        "# indeterminada y compute la cantidad de mensajes positivos\n",
        "#\n",
        "# Rta/\n",
        "# 8284\n",
        "#\n",
        "import warnings\n",
        "# init\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "rows_ = rows.copy()\n",
        "rows_null = rows_[rows_.qualification.isnull()]\n",
        "\n",
        "rows_null['message_stemmed'] = rows_null.message.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()])).str.lower()\n",
        "\n",
        "rows_null\n",
        "\n",
        "dtm_null = count_vect.transform(rows_null.message_stemmed)\n",
        "\n",
        "y_pred_positive = (clf.predict(dtm_null))\n",
        "\n",
        "int(sum(y_pred_positive))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "08-002_analisis_de_sentimientos_en_amazon_usando_bayes.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nteract": {
      "version": "0.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
